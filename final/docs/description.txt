6. Архитектура

   Кратко Keycloak представляет собой IdP систему ( идентити провайдер ). 
   Т.е. пользователи авторизуются в "некой системе" используя Keycloak.

   Кеуkloak через модуль "kafka-spi-module" отправляет события в Kafka в топик "keycloak-events"
   События из топика "keycloak-events" с помощью "Kafka-connect" отправляются в Elasticsearch для визуализации через Kiban-у.
   
   Также эти же события из топика "keycloak-events" обрабатываются сервисом "kafka-streams" для формирования топиков:
   . malicious-UNF - события "User nof found" агрегированные по IP адресу
   . malicious-IUC - события "Invalid user credentials" агрегированные по "realmId + userId"
   . new-user-location - события "успешное подключение пользователя из новой локации"
   . known-user-location - в Kafka-steams представляет собой таблицу со спиком уже известных локаций

   Ksqldb используется для "тестирования" удаления сообщений из топика (таблицы) "known-user-location"




7. Краткое описание

   1. в качестве модуля для отправки событий из Keycloak в Kafka используется проект:
     https://github.com/SnuK87/keycloak-kafka.git

   2. Каждое сообщения представляет собой JSON в котором есть поле "error"
      Виды используемых "error" сообщений:
      . "user_not_found" ( кратко UNF )
      . "invalid_user_credentials" ( кратко IUC )
      . null - при успешной аутенификации




8. Краткое описание (продолжение)
   
   Dto --> Data Transfer Object (DTO)
   один из шаблонов проектирования, используется для передачи данных между подсистемами приложения




9. Структура проекта
   . докерфайлы для сборки компонентов проекта
   ...
   ...




10. Исходный код “топологии” и “kafka-streams” для детектирования “подбора пользователя”

    Показаны исходники "топологии" и "кафка стрим" для детектирования “подбора пользователя”

    в топологии описывается "цепочка трансформаций" при обработке событий.
    этапы:
    . фильтрации по ошибке "user_not_found"
    . формироваение "нового" ключа "ipAddress"
    . агрегация по новому ключу в рамках "окна"
    . выборка событий которые превысили порог событий
    . формироваение "нового" ключа "ipAddress" + "окно события"
    . отправка событий в выходной топик

    в классе "KafkaStream" из топологии формируется стрим "maliciousUserNotFound"




11. Исходный код “топологии” и “kafka-streams” для детектирования “подбора пароля”
    
    аналогичен "предыдущему слайду"
    разница только в "фильтре" ошибки ( тут invalid_user_credentials )
    ключах агрегации 
    выходном топике



 
12. Исходный код “топологии” и “kafka-streams” для детектирования “новой локации пользователя”

    отфильтровываются только "успешные подключения"
    формируется новый ключ "userId + realmId + ipAddress"
    производится "lefjoin" с таблицей созданной из топика "known-user-location"
    и если такого "ключа" в таблице "known-user-location" не найдено, то событие отправляется в топики
    "new-user-location"
    и "known-user-location"

    при этом осуществляется необходимая сериализация сообщений




13. Вырезка исходного кода класса StreamApp и dockerfile + docker-compose для итоговой сборки 

    Тут показан "майн" класс StreamApp который используется для запуска всех "трех" дочерних стримов
    
    также показан докер файл использующийся для сборки "контейнера кафка стримс", а также показана вырезка из docker-compose файла,
    который используется для старта контейнера




14. Dockerfile + docker-compose для сборки Keycloak c “внешним” модулем “keycloak-kafka”
    
    Тут показан докер файл  использующийся для сборки конейнера Keyckloak с модулем kafka,
    а также показана вырезка docker-compose файла, который запускает этот контейнер




15. Запуск проекта и запуска скиптов конфигурации “kafka”, “keycloak”, “kafka-connect”, “elasticsearch” и “kibana”

    Используя Makefile запускаем все необходимые для проекта контейнеры,
    а также производим их post-конфигурацию
     . создание топиков в kafka
     . конфигурация Keycloak для отправки событий в Kafka
     . конфигурация Kafka-Connect, ElasticSearch и Kibana, для визуализации событий в ELK

    и проверяем что они успешно стартанули

 


16. Список топиков в “kafdrop” полученый после запуска скриптов конфигурации

  видим, что присутствуют топики созданные при конфигурации,
  а также "технические" топики":
   . kafka-connect
   . kafka-steeams
   . ksqldb




17. Проверка “keycloak”, что модуль отправки событий в kafka подключен

  видим, что модуль "kafka" присутствует в списке "Event listeners"




18. Пример запуска скриптов для тестрование и “исходный код” одного и скрипта

  Скрипты для тестирования работоспособности "kafka-streams" будем запускать также через Makefile

  т.е. есть три скрипта для тестирование вариантов детектирования "мошеннической активности"

  Пример одного из скриптов также представлен на скрине:
   
  т.е. это скрипт для проверки детектирования "новых локаций пользователяш"




19. Запуск скрипта для проверки “подбора пользователя”

    наблюдаем лог вывода скрипта, а также смотрим, что сообщений появляются во входном топике "keycloak-events"




20. Проверка содержимого топика “malicious-user-not-found”:

    проверяем, что через некоторое время ( примерно 2 мин) ожидаемые сообщения появились




21. Запуск скрипта для проверки “подбора пароля”

    наблюдаем лог вывода скрипта, а также смотрим, что сообщений появляются во входном топике "keycloak-events"




22. Проверка содержимого топика “malicious-invalid-user-credentials”
 
    проверяем, что через некоторое время ( примерно 2 мин) ожидаемые сообщения появились




23. Запуск скрипта для проверки “новой локации пользователя”
   
    наблюдаем лог вывода скрипта, а также смотрим, что сообщений появляются во входном топике "keycloak-events"




24. Проверка содержимого топиков “new-user-location” и “known-user-location”




25. Используя “KsqlDB” создаем новый stream “TEST_DELETES” из топика “known-user-location”

    Проверяем содержимое стрима "TEST_DELETES"

    Для теста "удаления известной локации пользователя" из топика “known-user-location” выбираем ключ с IP адресом "10.90.99.2"




26. Используя stream “TEST_DELETES” вставляем в топик “known-user-location” “tombstone” сообщение для локации с IP=10.90.99.2 

    На скрине "SELECT * from TEST_DELETES" было запущено, после повторного запуска "теста новой локации пользователя"




27. Повторно запустив скрипт для “тестирования новых локаций” успешно получили повторное появление сообщения для локации с IP=10.90.99.2

    Это скрины с Кафдроп, видим :
    . в топике "new-user-location" повторное сообщение с локацией IP=10.90.99.2
    . в топике "known-user-ocation" видим и "tombstone" сообщение и повторное сообщение с IP=10.90.99.2

    т.е. получили ожидаемый повтор

    по остальным сообщениям повторов нет




28. После проведения всех тестов, проверяем 
    интеграцию Kafka + Kafka-Connect + ELK для визуализации событий топика “keycloak-events” 

    т.е. заходим в Kibana и проверяем события в топике "keycloak-events"




29. Выводы:
    . Протестировали технологии kafka-streams для анализа событий Keycloak
    . Используя Kafka-Connect и ELK научились визуализировать события Keycloak
    . Потрогали KsqlDB

    Планы по развитию:
    . Для локации вместо IP использовать GeoLite
    . Попробовать использовать внешнюю БД + debezium, для формирования топика “known-user-location”
 
